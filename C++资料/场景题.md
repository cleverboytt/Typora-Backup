**1、****<font style="background-color:#FFFF00;">3000个数里面找最大的k个数</font>**：堆排序，构造大/小根堆：从后到前，从倒数第一个非叶子节点len/2-1开始（buildHeap）；从上到下，根和大于根的最大子节点交换（adjustOnce）；排序：首尾交换，重新构造大/小根堆，重复操作。

时间复杂度：O(nlogk)

排序算法场景分析：

数据量较少：插入、选择

基本有序（原本有序，新插入元素）：插入、冒泡

随机分布：快速

数据量大：快速、堆、归并

稳定：归并、冒泡、插入、桶、基数

不稳定：选择、快速、堆

**<font style="background-color:#FFFF00;">外部排序：</font>**将数据分成若干个小块，每个小块都能够放入内存中进行排序。通过归并排序等算法对每个小块进行排序后，再将所有小块合并成一个有序的大块（大根堆or小根堆）。

**2、****<font style="background-color:yellow;">有一个文件，里面全部是不重复的整数，整数最大值不超过七位数，input是文件，output是一个文件，将文件里面整数排</font>****序**：使用位图，每个位只代表整数是否存在，遍历每个读取到的整数，将位图中对应索引的值设为true，遍历位图，按顺序将值位true的数写入文件。

如何优化离散数据分布：采用分段位图，将数据分为多个段，仅当段内有数据时，才分配内存。

**3、****<font style="background-color:yellow;">亿级别搜索日志</font>**，从中筛选出**<font style="background-color:yellow;">top10的热词</font>**。将数据分成多个小块，并在多台计算机上同时运行分布式程序。每个计算机都执行“map”和“reduce”两个阶段的操作：Map阶段：输入数据被分割成小块，每个块由一个特定的计算机节点处理。对于每个块，该节点会应用用户定义的“map”函数，将输入键值对映射为中间键值对。比如可以把文本文件中的每一行转化为(word, 1)的形式。Reduce阶段：所有中间键值对被收集合并，然后按照键进行排序，最终输出结果。每个计算节点都会应用用户定义的“reduce”函数，将具有相同键的值聚合在一起，生成最终结果。例如在上述例子中，reduce阶段可以把所有key为word的value相加，得到这个单词在文本中出现的次数。

**4、**两个**<font style="background-color:yellow;">50亿url的文件</font>**，找到其中**<font style="background-color:yellow;">相同的url</font>**，也是哈希分桶，接着内存够用了，接着在桶内用哈希表再查找相同的，也可以构建前缀树进行查找，若长度不会很长的话。

**5、**海量数据如何寻找中位数，从二进制最高位开始以0和1进行分治，找中点。

**6、****<font style="background-color:yellow;">秒杀系统</font>**：发布秒杀活动时，将商品与库存写入redis。当用户进行抢购时，直接对redis的库存进行操作。扣减redis内库存数量后，发送扣减成功的消息到消息队列，由后续的订单服务和支付服务进行处理。最后再由mysql进行库存扣减。**<font style="background-color:yellow;">超卖问题</font>**：秒杀时分两步：首先判断库存是否充足，之后扣减库存数量。这两步必须要保证操作原子性；少卖问题：扣减了库存，但是消息没发出，订单生成失败，导致没有卖出去。扣减库存后，发送消息队列需要有重试策略，如果消息发送失败需要重试，超过重试次数后，则需要持久化到磁盘记录下来，由补偿服务扫描是否存在少卖问题，进行后续业务处理。

**7、****<font style="background-color:yellow;">40亿个qq号怎么去重</font>**：大数据去重可以是用bitmap，可以分批次读入内存（将Bitmap按照一定的规则进行划分（如按照数据区间划分，0-10000是一个Bitmap），将其分成若干个较小的区块，每个区块对应一个Bitmap。这样可以避免一次性将整个Bitmap加载到内存中），将qq号对应的位置置为1，最后遍历位图即可得到去重过的qq号。进一步节省空间可以考虑使用位图压缩算法，或者多层级的位图，适用于较稀疏的数据分布。若对结果的准确性没有很严格的要求，也可以使用布隆过滤器，会存在一定的误判。

**8、****<font style="background-color:yellow;">密码如何传输和存储</font>**：传输一定得用https，在服务端，通过原密码+salt经过哈希加密算法（可以使用慢哈希）进行比对，服务端一般不存储原始密码，而比较加密之后的密钥。多次输错后如何锁定：限制IP或限制用户，一般来说限制IP。基于Redis，key为标识IP登录的唯一标识符，value为输错次数；或者直接在mysql表内存储相应字段也可以。

**9、****<font style="background-color:yellow;">推荐系统设计：</font>**召回：粗筛->精排粗筛：对每个视频抽取特征进行聚类，计算每个视频和类中心的相关性，按照相关性进行排序。用户特征到来后，计算和每一类中心的相关性，筛选出相关性最高的前k类视频。精排：在前k类视频中，对每一类选出和相关性正相关数量的视频，推荐给用户

**10、****<font style="background-color:yellow;">广告系统设计：</font>**

**<font style="background-color:yellow;">架构层面：</font>**

前端展示：用户通过微信客户端查看朋友圈页面。后端服务：负载均衡器分发请求，广告投放服务选择广告，用户画像服务构建用户画像，广告效果监测服务记录效果。数据存储：使用 MySQL存储数据，Redis 缓存高频数据，Kafka 或 RabbitMQ 处理异步任务。 （存储用户数据（基本信息、行为数据如点击历史、偏好设置），广告数据（存储广告的基本信息，投放规则，排期信息等），广告投放记录（记录广告的展示、点击等行为））**<font style="background-color:yellow;">业务逻辑层面：</font>**

广告选择：根据用户画像和广告排期规则选择广告。广告展示：展示广告给用户，并从缓存或数据库中获取广告数据。广告点击处理：记录点击行为，并将用户添加到广告屏蔽列表中。广告效果监测：记录点击率和转化率等指标，并优化广告投放策略。

**11、****<font style="background-color:yellow;">分布式kv一致性哈希：</font>**一致性哈希：包含两步：对存储节点进行哈希计算，如计算存储节点的IP哈希值，结果对2^32取余；对key进行哈希计算，结果对2^32取余；根据key的哈希值，顺时针寻找到的第一个存储节点，就是存储该key的存储节点。在一致哈希算法中，如果增加或者移除一个节点，仅影响该节点在哈希环上顺时针相邻的后继节点，其它数据也不会受到影响，但是一致性哈希算法并不保证节点能够在哈希环上分布均匀。为了解决分布不均匀的问题，加入虚拟节点，因为节点越多，分布越均匀。不再将真实节点映射到哈希环上，而是将虚拟节点映射到哈希环上，并将虚拟节点映射到实际节点，所以这里有「两层」映射关系。

